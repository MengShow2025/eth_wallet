#!/usr/bin/env python3
"""
ETH é’±åŒ…ç”Ÿæˆä¸åœ°å€æ¯”å¯¹æœåŠ¡ - äº‘æœåŠ¡å™¨ä¼˜åŒ–ç‰ˆ v3
- æ”¯æŒç¯å¢ƒå˜é‡é…ç½®
- æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
- ä¼˜åŒ–å†…å­˜ä½¿ç”¨
- æ”¯æŒ systemd æœåŠ¡
- å®Œå–„çš„æ—¥å¿—è®°å½•
- æ”¯æŒ Gunicorn ç”Ÿäº§éƒ¨ç½²
"""

import os
import sys
import time
import json
import secrets
import pickle
import threading
import glob
import argparse
import logging
import signal
from datetime import datetime
from typing import Optional, Set
from pathlib import Path

# Web æ¡†æ¶
from flask import Flask, render_template, jsonify
from flask_socketio import SocketIO, emit

# ä»¥å¤ªåŠ
from eth_account import Account

# æ•°æ®åº“
import mysql.connector
from mysql.connector import pooling

# Bloom Filter
from pybloom_live import BloomFilter

# ==================== é…ç½®ç®¡ç† ====================

class Config:
    """é…ç½®ç±» - æ”¯æŒç¯å¢ƒå˜é‡å’Œå‘½ä»¤è¡Œå‚æ•°"""

    # æ•°æ®åº“é…ç½®
    DB_HOST = os.getenv('DB_HOST', 'sh-cynosdbmysql-grp-g1mnllo4.sql.tencentcdb.com')
    DB_PORT = int(os.getenv('DB_PORT', '26937'))
    DB_USER = os.getenv('DB_USER', 'root')
    DB_PASSWORD = os.getenv('DB_PASSWORD', 'RMuxA3kh')
    DB_NAME = os.getenv('DB_NAME', 'token')
    DB_POOL_SIZE = int(os.getenv('DB_POOL_SIZE', '5'))

    # æ•°æ®ç›®å½•é…ç½®
    DATA_DIR = os.getenv('DATA_DIR', './data/databases32G')
    TEMPLATE_DIR = os.getenv('TEMPLATE_DIR', './crypto-wallet-generator')

    # æ•°æ®æºé…ç½®
    USE_DATABASE = os.getenv('USE_DATABASE', 'true').lower() == 'true'

    # æœåŠ¡é…ç½®
    HOST = os.getenv('HOST', '0.0.0.0')
    PORT = int(os.getenv('PORT', '5001'))
    NUM_WORKERS = int(os.getenv('NUM_WORKERS', '8'))

    # Bloom Filter é…ç½®
    BLOOM_ERROR_RATE = float(os.getenv('BLOOM_ERROR_RATE', '0.000001'))

    # æ—¥å¿—é…ç½®
    LOG_LEVEL = os.getenv('LOG_LEVEL', 'INFO')
    LOG_FILE = os.getenv('LOG_FILE', 'eth_wallet_service.log')

    @classmethod
    def get_db_config(cls):
        """è·å–æ•°æ®åº“é…ç½®"""
        return {
            'host': cls.DB_HOST,
            'port': cls.DB_PORT,
            'user': cls.DB_USER,
            'password': cls.DB_PASSWORD,
            'database': cls.DB_NAME,
            'pool_name': 'eth_pool',
            'pool_size': cls.DB_POOL_SIZE
        }

# ==================== æ—¥å¿—é…ç½® ====================

def setup_logging(log_level='INFO', log_file=None):
    """é…ç½®æ—¥å¿—"""
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'

    handlers = [logging.StreamHandler(sys.stdout)]
    if log_file:
        handlers.append(logging.FileHandler(log_file))

    logging.basicConfig(
        level=getattr(logging, log_level.upper()),
        format=log_format,
        handlers=handlers
    )

    return logging.getLogger(__name__)

logger = setup_logging(Config.LOG_LEVEL, Config.LOG_FILE)

# ==================== å…¨å±€å˜é‡ ====================

app = Flask(__name__,
            template_folder=Config.TEMPLATE_DIR,
            static_folder=Config.TEMPLATE_DIR)
socketio = SocketIO(app, cors_allowed_origins="*", async_mode='threading')

bloom_filter: Optional[BloomFilter] = None
address_set: Set[str] = set()
db_pool = None
is_running = False
shutdown_flag = False

stats = {
    'generated': 0,
    'matched': 0,
    'start_time': None,
    'speed': 0,
    'load_time': 0,
    'total_addresses': 0
}

# ==================== æ•°æ®åº“æ“ä½œ ====================

def create_tables():
    """åˆ›å»ºæ•°æ®åº“è¡¨"""
    try:
        conn = db_pool.get_connection()
        cursor = conn.cursor()

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS eth_wallet (
                id              BIGINT AUTO_INCREMENT PRIMARY KEY,
                address         VARCHAR(42) NOT NULL UNIQUE,
                private_key     VARCHAR(66) NOT NULL,
                balance         DECIMAL(36,18) DEFAULT 0,
                matched_at      TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                INDEX idx_eth_wallet_address (address)
            ) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
        """)

        conn.commit()
        cursor.close()
        conn.close()
        logger.info("âœ… eth_wallet è¡¨å·²å°±ç»ª")
    except Exception as e:
        logger.error(f"âŒ åˆ›å»ºè¡¨å¤±è´¥: {e}")
        raise

# ==================== Bloom Filter åŠ è½½ ====================

def load_bloom_filter_from_database():
    """ä»æ•°æ®åº“åŠ è½½åœ°å€åˆ° Bloom Filter"""
    global bloom_filter, address_set, stats

    logger.info("ğŸ“¥ æ­£åœ¨ä»æ•°æ®åº“åŠ è½½åœ°å€...")
    start_time = time.time()

    try:
        conn = db_pool.get_connection()
        cursor = conn.cursor()

        # å…ˆè·å–æ€»æ•°
        logger.info("   ç»Ÿè®¡åœ°å€æ€»æ•°...")
        cursor.execute("SELECT COUNT(*) FROM eth_active_addresses")
        total_addresses = cursor.fetchone()[0]
        logger.info(f"   æ‰¾åˆ° {total_addresses:,} ä¸ªåœ°å€")

        if total_addresses == 0:
            logger.warning("âš ï¸  æ•°æ®åº“ä¸­æ²¡æœ‰åœ°å€æ•°æ®")
            cursor.close()
            conn.close()
            return

        # åˆ›å»º Bloom Filter
        logger.info("   åˆ›å»º Bloom Filter...")
        bloom_filter = BloomFilter(
            capacity=total_addresses + 1000000,
            error_rate=Config.BLOOM_ERROR_RATE
        )

        # åˆ†æ‰¹åŠ è½½åœ°å€
        logger.info("   åŠ è½½åœ°å€åˆ° Bloom Filter...")
        batch_size = 100000
        loaded = 0

        cursor.execute("SELECT address FROM eth_active_addresses")

        while True:
            rows = cursor.fetchmany(batch_size)
            if not rows:
                break

            for row in rows:
                addr = row[0]
                # ç»Ÿä¸€æ ¼å¼ï¼šæ·»åŠ  0x å‰ç¼€å¹¶è½¬å°å†™
                full_addr = f"0x{addr.lower()}" if not addr.startswith('0x') else addr.lower()
                bloom_filter.add(full_addr)
                address_set.add(full_addr)
                loaded += 1

            if loaded % 1000000 == 0:
                logger.info(f"         å·²åŠ è½½: {loaded:,} / {total_addresses:,}")

        cursor.close()
        conn.close()

        elapsed = time.time() - start_time
        memory_mb = bloom_filter.num_bits / 8 / 1024 / 1024

        logger.info(f"\nâœ… åŠ è½½å®Œæˆ!")
        logger.info(f"   è€—æ—¶: {elapsed:.1f} ç§’")
        logger.info(f"   åœ°å€æ•°: {len(address_set):,}")
        logger.info(f"   Bloom Filter å†…å­˜: ~{memory_mb:.1f} MB")

        stats['load_time'] = elapsed
        stats['total_addresses'] = len(address_set)

    except Exception as e:
        logger.error(f"âŒ ä»æ•°æ®åº“åŠ è½½å¤±è´¥: {e}")
        raise

def load_bloom_filter_from_pickle():
    """ä» pickle æ–‡ä»¶åŠ è½½åœ°å€åˆ° Bloom Filter"""
    global bloom_filter, address_set, stats

    logger.info("ğŸ“¥ æ­£åœ¨ä»æœ¬åœ° pickle æ–‡ä»¶åŠ è½½...")
    start_time = time.time()

    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dir = Path(Config.DATA_DIR)
    if not data_dir.exists():
        logger.error(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        raise FileNotFoundError(f"æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")

    # è·å–æ‰€æœ‰ pickle æ–‡ä»¶
    pkl_files = sorted(data_dir.glob('data*.pkl'))
    if not pkl_files:
        logger.error(f"âŒ æœªæ‰¾åˆ° pickle æ–‡ä»¶: {data_dir}/data*.pkl")
        raise FileNotFoundError(f"æœªæ‰¾åˆ° pickle æ–‡ä»¶")

    logger.info(f"   æ‰¾åˆ° {len(pkl_files)} ä¸ªæ•°æ®æ–‡ä»¶")

    # åŠ è½½æ‰€æœ‰åœ°å€
    total_addresses = 0
    all_addresses = []

    for i, pkl_file in enumerate(pkl_files, 1):
        logger.info(f"   [{i}/{len(pkl_files)}] åŠ è½½: {pkl_file.name}")
        try:
            with open(pkl_file, 'rb') as f:
                addresses = pickle.load(f)
                all_addresses.append(addresses)
                total_addresses += len(addresses)
            logger.info(f"         åŒ…å« {len(addresses):,} ä¸ªåœ°å€")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {pkl_file}: {e}")
            raise

    logger.info(f"\n   æ€»åœ°å€æ•°: {total_addresses:,}")

    # åˆ›å»º Bloom Filter
    logger.info("   åˆ›å»º Bloom Filter...")
    bloom_filter = BloomFilter(
        capacity=total_addresses + 1000000,
        error_rate=Config.BLOOM_ERROR_RATE
    )

    # æ‰¹é‡æ·»åŠ åˆ° Bloom Filter
    logger.info("   æ·»åŠ åœ°å€åˆ° Bloom Filter...")
    loaded = 0

    for addresses in all_addresses:
        for addr in addresses:
            # ç»Ÿä¸€æ ¼å¼ï¼šæ·»åŠ  0x å‰ç¼€å¹¶è½¬å°å†™
            full_addr = f"0x{addr.lower()}" if not addr.startswith('0x') else addr.lower()
            bloom_filter.add(full_addr)
            address_set.add(full_addr)
            loaded += 1

            if loaded % 10000000 == 0:
                logger.info(f"         å·²åŠ è½½: {loaded:,} / {total_addresses:,}")

    elapsed = time.time() - start_time
    memory_mb = bloom_filter.num_bits / 8 / 1024 / 1024

    logger.info(f"\nâœ… åŠ è½½å®Œæˆ!")
    logger.info(f"   è€—æ—¶: {elapsed:.1f} ç§’")
    logger.info(f"   åœ°å€æ•°: {len(address_set):,}")
    logger.info(f"   Bloom Filter å†…å­˜: ~{memory_mb:.1f} MB")

    stats['load_time'] = elapsed
    stats['total_addresses'] = len(address_set)

# ==================== é’±åŒ…ç”Ÿæˆ ====================

def generate_eth_wallet():
    """ç”Ÿæˆ ETH é’±åŒ…"""
    private_key = secrets.token_hex(32)
    private_key_bytes = bytes.fromhex(private_key)
    account = Account.from_key(private_key_bytes)

    return {
        'address': account.address.lower(),
        'private_key': '0x' + private_key
    }

def check_and_save_match(wallet: dict) -> bool:
    """æ£€æŸ¥åœ°å€æ˜¯å¦åŒ¹é…å¹¶ä¿å­˜"""
    global stats

    address = wallet['address']

    # Bloom Filter å¿«é€Ÿæ£€æŸ¥
    if address not in bloom_filter:
        return False

    # ç²¾ç¡®éªŒè¯
    if address not in address_set:
        return False  # å‡é˜³æ€§

    # çœŸæ­£åŒ¹é…ï¼ä¿å­˜åˆ°æ•°æ®åº“
    try:
        conn = db_pool.get_connection()
        cursor = conn.cursor()

        cursor.execute("""
            INSERT IGNORE INTO eth_wallet (address, private_key)
            VALUES (%s, %s)
        """, (address, wallet['private_key']))
        conn.commit()

        cursor.close()
        conn.close()

        stats['matched'] += 1
        logger.info(f"ğŸ‰ å‘ç°åŒ¹é…! {address}")
        return True
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")
        return False

def wallet_generator_worker():
    """é’±åŒ…ç”Ÿæˆå·¥ä½œçº¿ç¨‹"""
    global stats, is_running

    while is_running and not shutdown_flag:
        try:
            wallet = generate_eth_wallet()
            stats['generated'] += 1

            if check_and_save_match(wallet):
                # å‘ç°åŒ¹é…ï¼é€šçŸ¥å‰ç«¯
                match_data = {
                    'address': wallet['address'],
                    'private_key': wallet['private_key'],
                    'matched_at': datetime.now().isoformat(),
                    'total_matched': stats['matched']
                }
                socketio.emit('wallet_matched', match_data)
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆé’±åŒ…é”™è¯¯: {e}")
            time.sleep(0.1)

def start_generation():
    """å¯åŠ¨é’±åŒ…ç”Ÿæˆ"""
    global is_running, stats

    if is_running:
        return False

    is_running = True
    stats['generated'] = 0
    stats['matched'] = 0
    stats['start_time'] = time.time()
    stats['speed'] = 0

    # å¯åŠ¨å¤šä¸ªå·¥ä½œçº¿ç¨‹
    num_workers = Config.NUM_WORKERS
    for _ in range(num_workers):
        thread = threading.Thread(target=wallet_generator_worker, daemon=True)
        thread.start()

    # å¯åŠ¨é€Ÿåº¦è®¡ç®—çº¿ç¨‹
    def speed_calculator():
        last_count = 0
        while is_running and not shutdown_flag:
            time.sleep(1)
            current = stats['generated']
            stats['speed'] = current - last_count
            last_count = current

    threading.Thread(target=speed_calculator, daemon=True).start()

    logger.info(f"ğŸš€ å·²å¯åŠ¨ {num_workers} ä¸ªç”Ÿæˆçº¿ç¨‹")
    return True

def stop_generation():
    """åœæ­¢é’±åŒ…ç”Ÿæˆ"""
    global is_running
    is_running = False
    logger.info("â¹ï¸ ç”Ÿæˆå·²åœæ­¢")

# ==================== Flask è·¯ç”± ====================

@app.route('/')
def index():
    return render_template('wallet_generator.html')

@app.route('/api/stats')
def get_stats():
    elapsed = time.time() - stats['start_time'] if stats['start_time'] else 0
    return jsonify({
        'generated': stats['generated'],
        'matched': stats['matched'],
        'speed': stats['speed'],
        'elapsed': int(elapsed),
        'is_running': is_running,
        'total_addresses': stats['total_addresses'],
        'load_time': stats['load_time']
    })

@app.route('/api/matches')
def get_matches():
    """è·å–æ‰€æœ‰åŒ¹é…çš„é’±åŒ…"""
    try:
        conn = db_pool.get_connection()
        cursor = conn.cursor(dictionary=True)

        cursor.execute("""
            SELECT address, private_key, matched_at
            FROM eth_wallet
            ORDER BY matched_at DESC
            LIMIT 100
        """)

        matches = cursor.fetchall()
        cursor.close()
        conn.close()

        for m in matches:
            if m['matched_at']:
                m['matched_at'] = m['matched_at'].isoformat()

        return jsonify(matches)
    except Exception as e:
        logger.error(f"âŒ è·å–åŒ¹é…è®°å½•å¤±è´¥: {e}")
        return jsonify([])

@app.route('/health')
def health():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    return jsonify({
        'status': 'healthy',
        'bloom_filter_loaded': bloom_filter is not None,
        'total_addresses': len(address_set),
        'is_running': is_running
    })

# ==================== WebSocket äº‹ä»¶ ====================

@socketio.on('connect')
def handle_connect():
    logger.info('å®¢æˆ·ç«¯å·²è¿æ¥')
    emit('stats_update', {**stats, 'total_addresses': len(address_set)})

@socketio.on('start')
def handle_start():
    if start_generation():
        emit('status', {'message': 'ç”Ÿæˆå·²å¯åŠ¨', 'is_running': True})
    else:
        emit('status', {'message': 'å·²åœ¨è¿è¡Œä¸­', 'is_running': True})

@socketio.on('stop')
def handle_stop():
    stop_generation()
    emit('status', {'message': 'ç”Ÿæˆå·²åœæ­¢', 'is_running': False})

def stats_broadcaster():
    """å®šæœŸå¹¿æ’­ç»Ÿè®¡æ•°æ®"""
    while not shutdown_flag:
        if is_running:
            socketio.emit('stats_update', {
                'generated': stats['generated'],
                'matched': stats['matched'],
                'speed': stats['speed'],
                'is_running': is_running,
                'total_addresses': stats['total_addresses']
            })
        time.sleep(1)

# ==================== ä¿¡å·å¤„ç† ====================

def signal_handler(signum, frame):
    """å¤„ç†é€€å‡ºä¿¡å·"""
    global shutdown_flag
    logger.info(f"\næ”¶åˆ°é€€å‡ºä¿¡å· {signum}ï¼Œæ­£åœ¨å…³é—­æœåŠ¡...")
    shutdown_flag = True
    stop_generation()
    sys.exit(0)

signal.signal(signal.SIGINT, signal_handler)
signal.signal(signal.SIGTERM, signal_handler)

# ==================== ä¸»å‡½æ•° ====================

def main():
    global db_pool

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ETH é’±åŒ…ç”Ÿæˆä¸æ¯”å¯¹æœåŠ¡')
    parser.add_argument('--host', default=Config.HOST, help='ç›‘å¬åœ°å€')
    parser.add_argument('--port', type=int, default=Config.PORT, help='ç›‘å¬ç«¯å£')
    parser.add_argument('--workers', type=int, default=Config.NUM_WORKERS, help='å·¥ä½œçº¿ç¨‹æ•°')
    parser.add_argument('--data-dir', default=Config.DATA_DIR, help='æ•°æ®ç›®å½•')
    parser.add_argument('--log-level', default=Config.LOG_LEVEL, help='æ—¥å¿—çº§åˆ«')
    parser.add_argument('--auto-start', action='store_true', help='è‡ªåŠ¨å¼€å§‹ç”Ÿæˆ')
    args = parser.parse_args()

    # æ›´æ–°é…ç½®
    Config.HOST = args.host
    Config.PORT = args.port
    Config.NUM_WORKERS = args.workers
    Config.DATA_DIR = args.data_dir
    Config.LOG_LEVEL = args.log_level

    # é‡æ–°é…ç½®æ—¥å¿—
    global logger
    logger = setup_logging(Config.LOG_LEVEL, Config.LOG_FILE)

    logger.info("=" * 60)
    logger.info("ğŸš€ ETH é’±åŒ…ç”Ÿæˆä¸æ¯”å¯¹æœåŠ¡ v3 (äº‘æœåŠ¡å™¨ä¼˜åŒ–ç‰ˆ)")
    logger.info("=" * 60)
    logger.info(f"é…ç½®ä¿¡æ¯:")
    logger.info(f"  - æ•°æ®ç›®å½•: {Config.DATA_DIR}")
    logger.info(f"  - ç›‘å¬åœ°å€: {Config.HOST}:{Config.PORT}")
    logger.info(f"  - å·¥ä½œçº¿ç¨‹: {Config.NUM_WORKERS}")
    logger.info(f"  - æ—¥å¿—çº§åˆ«: {Config.LOG_LEVEL}")
    logger.info("=" * 60)

    try:
        # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± 
        logger.info("\nğŸ“¡ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± ...")
        db_pool = pooling.MySQLConnectionPool(**Config.get_db_config())
        logger.info("âœ… æ•°æ®åº“è¿æ¥æ± å·²å°±ç»ª")

        # åˆ›å»ºè¡¨
        create_tables()

        # æ ¹æ®é…ç½®é€‰æ‹©æ•°æ®æº
        if Config.USE_DATABASE:
            logger.info("\nğŸ“Š æ•°æ®æº: æ•°æ®åº“")
            load_bloom_filter_from_database()
        else:
            logger.info("\nğŸ“Š æ•°æ®æº: æœ¬åœ° pickle æ–‡ä»¶")
            load_bloom_filter_from_pickle()

        # å¯åŠ¨ç»Ÿè®¡å¹¿æ’­çº¿ç¨‹
        broadcaster = threading.Thread(target=stats_broadcaster, daemon=True)
        broadcaster.start()

        # è‡ªåŠ¨å¼€å§‹ç”Ÿæˆ
        if args.auto_start:
            logger.info("\nğŸš€ è‡ªåŠ¨å¯åŠ¨é’±åŒ…ç”Ÿæˆ...")
            start_generation()

        # å¯åŠ¨ Flask æœåŠ¡
        logger.info(f"\nğŸŒ å¯åŠ¨ Web æœåŠ¡...")
        logger.info(f"   è®¿é—®: http://{Config.HOST}:{Config.PORT}")
        logger.info(f"   å¥åº·æ£€æŸ¥: http://{Config.HOST}:{Config.PORT}/health")
        logger.info("=" * 60)

        socketio.run(
            app,
            host=Config.HOST,
            port=Config.PORT,
            debug=False,
            allow_unsafe_werkzeug=True
        )

    except Exception as e:
        logger.error(f"âŒ æœåŠ¡å¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == '__main__':
    main()
